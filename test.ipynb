{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "categories = [\"soc.religion.christian\", \"sci.space\", \"talk.politics.mideast\", \"rec.sport.baseball\"]\n",
    "cat_dict = {} # Contains raw training data organized by category\n",
    "cat_dict_test = {} # Contains raw test data organized by category\n",
    "for cat in categories:\n",
    "    cat_dict[cat] = datasets.fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=[cat]).data\n",
    "    cat_dict_test[cat] = datasets.fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=[cat]).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_dict['soc.religion.christian'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "def tokenize(text, stopwords, max_len = 20):\n",
    "    return [token for token in gensim.utils.simple_preprocess(text, max_len=max_len) if token not in stopwords]\n",
    "\n",
    "cat_dict_tagged_train = {} # Contains clean tagged training data organized by category. To be used for the training corpus.\n",
    "cat_dict_test_clean = {} # Contains clean un-tagged training data organized by category.\n",
    "\n",
    "offset = 0 # Used for managing IDs of tagged documents\n",
    "for k, v in cat_dict.items():\n",
    "    cat_dict_tagged_train[k] = [gensim.models.doc2vec.TaggedDocument(tokenize(text, [], max_len=200), [i+offset]) for i, text in enumerate(v)]\n",
    "    offset += len(v)\n",
    "\n",
    "offset = 0\n",
    "for k, v in cat_dict_test.items():\n",
    "    cat_dict_test_clean[k] = [tokenize(text, [], max_len=200) for i, text in enumerate(v)]\n",
    "    offset += len(v)\n",
    "    \n",
    "# Eventually contains final versions of the training data to actually train the model\n",
    "train_corpus = [taggeddoc for taggeddoc_list in list(cat_dict_tagged_train.values()) for taggeddoc in taggeddoc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['wrote', 'in', 'response', 'to', 'dlecoint', 'garnet', 'acns', 'fsu', 'edu', 'darius_lecointe', 'was', 'paul', 'god', 'too', 'is', 'an', 'interpretation', 'of', 'the', 'words', 'of', 'paul', 'of', 'higher', 'priority', 'than', 'the', 'direct', 'word', 'of', 'jesus', 'in', 'matt', 'paul', 'begins', 'romans', 'with', 'if', 'someone', 'is', 'weak', 'in', 'the', 'faith', 'do', 'you', 'count', 'yourself', 'as', 'one', 'who', 'is', 'weak', 'in', 'the', 'faith', 'yes', 'but', 'what', 'does', 'the', 'bible', 'have', 'to', 'say', 'what', 'did', 'jesus', 'say', 'paul', 'closes', 'romans', 'with', 'on', 'the', 'other', 'hand', 'the', 'person', 'with', 'doubts', 'about', 'something', 'who', 'eats', 'it', 'anyway', 'is', 'guilty', 'because', 'he', 'isn', 'acting', 'on', 'his', 'faith', 'and', 'any', 'failure', 'to', 'act', 'on', 'faith', 'is', 'sin', 'gaus', 'isbn', 'have', 'you', 'read', 'the', 'ten', 'commandments', 'which', 'are', 'portion', 'of', 'the', 'law', 'have', 'you', 'read', 'jesus', 'word', 'in', 'matt', 'is', 'there', 'any', 'doubt', 'in', 'your', 'mind', 'about', 'what', 'is', 'right', 'and', 'what', 'is', 'sin', 'greek', 'hamartia', 'missing', 'the', 'mark', 'whereas', 'the', 'ten', 'commandments', 'and', 'jesus', 'words', 'in', 'matt', 'are', 'fairly', 'clear', 'are', 'they', 'not', 'matt', 'doesn', 'answer', 'your', 'question', 'breaking', 'bread', 'roughly', 'synonymous', 'with', 'eating', 'how', 'do', 'you', 'unite', 'this', 'concept', 'of', 'yours', 'with', 'the', 'ten', 'commandments', 'and', 'jesus', 'word', 'in', 'matt', 'or', 'they', 'assumed', 'that', 'the', 'ten', 'commandments', 'and', 'jesus', 'word', 'in', 'matt', 'actually', 'stood', 'for', 'something', 'perhaps', 'they', 'were', 'strong', 'in', 'the', 'faith', 'no', 'don', 'believe', 'that', 'paul', 'can', 'overrule', 'god', 'however', 'paul', 'was', 'writing', 'for', 'largely', 'gentile', 'audience', 'the', 'law', 'was', 'regarded', 'by', 'jews', 'at', 'the', 'time', 'and', 'now', 'as', 'binding', 'on', 'jews', 'but', 'not', 'on', 'gentiles', 'there', 'are', 'rules', 'that', 'were', 'binding', 'on', 'all', 'human', 'beings', 'the', 'so', 'called', 'noachic', 'laws', 'but', 'they', 'are', 'quite', 'minimal', 'the', 'issue', 'that', 'the', 'church', 'had', 'to', 'face', 'after', 'jesus', 'death', 'was', 'what', 'to', 'do', 'about', 'gentiles', 'who', 'wanted', 'to', 'follow', 'christ', 'the', 'decision', 'not', 'to', 'impose', 'the', 'law', 'on', 'them', 'didn', 'say', 'that', 'the', 'law', 'was', 'abolished', 'it', 'simply', 'acknowledged', 'that', 'fact', 'that', 'it', 'didn', 'apply', 'to', 'gentiles', 'thus', 'there', 'is', 'no', 'contradiction', 'with', 'mat', 'as', 'far', 'as', 'can', 'tell', 'both', 'paul', 'and', 'other', 'jewish', 'christians', 'did', 'continue', 'to', 'participate', 'in', 'jewish', 'worship', 'on', 'the', 'sabbath', 'thus', 'they', 'continued', 'to', 'obey', 'the', 'law', 'the', 'issue', 'was', 'and', 'is', 'with', 'gentile', 'christians', 'who', 'are', 'not', 'covered', 'by', 'the', 'law', 'or', 'at', 'least', 'not', 'by', 'the', 'ceremonial', 'aspects', 'of', 'it', 'jesus', 'dealt', 'mostly', 'with', 'jews', 'think', 'we', 'can', 'reasonably', 'assume', 'that', 'mat', 'was', 'directed', 'to', 'jewish', 'audience', 'he', 'did', 'interact', 'with', 'gentiles', 'few', 'times', 'the', 'centurion', 'whose', 'slave', 'was', 'healed', 'and', 'couple', 'of', 'others', 'the', 'terms', 'used', 'to', 'describe', 'the', 'centurion', 'see', 'luke', 'suggest', 'that', 'he', 'was', 'god', 'fearer', 'gentile', 'who', 'followed', 'god', 'but', 'had', 'not', 'adopted', 'the', 'whole', 'jewish', 'law', 'he', 'was', 'commended', 'by', 'jewish', 'elders', 'as', 'worthy', 'person', 'and', 'jesus', 'accepted', 'him', 'as', 'such', 'this', 'seems', 'to', 'me', 'to', 'indicate', 'that', 'jesus', 'accepted', 'the', 'prevailing', 'view', 'that', 'gentiles', 'need', 'not', 'accept', 'the', 'law', 'however', 'there', 'more', 'involved', 'if', 'you', 'want', 'to', 'compare', 'jesus', 'and', 'paul', 'on', 'the', 'law', 'in', 'order', 'to', 'get', 'full', 'picture', 'of', 'the', 'role', 'of', 'the', 'law', 'we', 'have', 'to', 'come', 'to', 'grips', 'with', 'paul', 'apparent', 'rejection', 'of', 'the', 'law', 'and', 'how', 'that', 'relates', 'to', 'jesus', 'commendation', 'of', 'the', 'law', 'at', 'least', 'as', 'read', 'paul', 'he', 'says', 'that', 'the', 'law', 'serves', 'purpose', 'that', 'has', 'been', 'in', 'certain', 'sense', 'superceded', 'again', 'this', 'issue', 'isn', 'one', 'of', 'the', 'abolition', 'of', 'the', 'law', 'in', 'the', 'middle', 'of', 'his', 'discussion', 'paul', 'notes', 'that', 'he', 'might', 'be', 'understood', 'this', 'way', 'and', 'assures', 'us', 'that', 'that', 'not', 'what', 'he', 'intends', 'to', 'say', 'rather', 'he', 'sees', 'the', 'law', 'as', 'primarily', 'being', 'present', 'to', 'convict', 'people', 'of', 'their', 'sinfulness', 'but', 'ultimately', 'it', 'an', 'impossible', 'standard', 'and', 'one', 'that', 'has', 'been', 'superceded', 'by', 'christ', 'paul', 'comments', 'are', 'not', 'the', 'world', 'clearest', 'here', 'and', 'not', 'everyone', 'agrees', 'with', 'my', 'reading', 'but', 'the', 'interesting', 'thing', 'to', 'notice', 'is', 'that', 'even', 'this', 'radical', 'position', 'does', 'not', 'entail', 'an', 'abolition', 'of', 'the', 'law', 'it', 'still', 'remains', 'as', 'an', 'uncompromising', 'standard', 'from', 'which', 'not', 'an', 'iota', 'or', 'dot', 'may', 'be', 'removed', 'for', 'its', 'purpose', 'of', 'convicting', 'of', 'sin', 'it', 'important', 'that', 'it', 'not', 'be', 'relaxed', 'however', 'for', 'christians', 'it', 'not', 'the', 'end', 'ultimately', 'we', 'live', 'in', 'faith', 'not', 'law', 'while', 'the', 'theoretical', 'categories', 'they', 'use', 'are', 'rather', 'different', 'in', 'the', 'end', 'think', 'jesus', 'and', 'paul', 'come', 'to', 'rather', 'similar', 'conclusion', 'the', 'quoted', 'passage', 'from', 'mat', 'should', 'be', 'taken', 'in', 'the', 'context', 'of', 'the', 'rest', 'of', 'the', 'sermon', 'on', 'the', 'mount', 'where', 'jesus', 'shows', 'us', 'how', 'he', 'interprets', 'the', 'law', 'the', 'not', 'an', 'iota', 'or', 'dot', 'would', 'suggest', 'rather', 'literal', 'reading', 'but', 'in', 'fact', 'that', 'not', 'jesus', 'approach', 'jesus', 'interpretations', 'emphasize', 'the', 'intent', 'of', 'the', 'law', 'and', 'stay', 'away', 'from', 'the', 'ceremonial', 'details', 'indeed', 'he', 'is', 'well', 'known', 'for', 'taking', 'rather', 'free', 'attitude', 'towards', 'the', 'sabbath', 'and', 'kosher', 'laws', 'some', 'scholars', 'claim', 'that', 'mat', 'needs', 'to', 'be', 'taken', 'in', 'the', 'context', 'of', 'st', 'cent', 'jewish', 'discussions', 'jesus', 'accuses', 'his', 'opponents', 'of', 'caring', 'about', 'giving', 'tenth', 'of', 'even', 'the', 'most', 'minor', 'herbs', 'but', 'neglecting', 'the', 'things', 'that', 'really', 'matter', 'justice', 'mercy', 'and', 'faith', 'and', 'caring', 'about', 'how', 'cups', 'and', 'plates', 'are', 'cleaned', 'but', 'not', 'about', 'the', 'fact', 'that', 'inside', 'the', 'people', 'who', 'use', 'them', 'are', 'full', 'of', 'extortion', 'and', 'rapacity', 'mat', 'this', 'and', 'the', 'discussion', 'later', 'in', 'mat', 'suggest', 'that', 'jesus', 'has', 'very', 'specific', 'view', 'of', 'the', 'law', 'in', 'mind', 'and', 'that', 'when', 'he', 'talks', 'about', 'maintaining', 'the', 'law', 'in', 'its', 'full', 'strength', 'he', 'is', 'thinking', 'of', 'these', 'aspects', 'of', 'it', 'paul', 'conclusion', 'is', 'similar', 'while', 'he', 'talks', 'about', 'the', 'law', 'being', 'superceded', 'all', 'of', 'the', 'specific', 'examples', 'he', 'gives', 'involve', 'the', 'ceremonial', 'law', 'such', 'as', 'circumcision', 'and', 'the', 'sabbath', 'he', 'is', 'quite', 'concerned', 'about', 'maintaining', 'moral', 'standards', 'the', 'net', 'result', 'of', 'this', 'is', 'that', 'when', 'paul', 'talks', 'about', 'the', 'law', 'being', 'superceded', 'and', 'jesus', 'talks', 'about', 'the', 'law', 'being', 'maintained', 'believe', 'they', 'are', 'talking', 'about', 'different', 'aspects', 'of', 'the', 'law', 'paul', 'is', 'embroiled', 'in', 'arguments', 'about', 'circumcision', 'as', 'is', 'natural', 'in', 'letters', 'responding', 'to', 'specific', 'situations', 'he', 'looking', 'at', 'the', 'aspect', 'of', 'the', 'law', 'that', 'is', 'currently', 'causing', 'trouble', 'the', 'law', 'as', 'specifically', 'jewish', 'ceremonies', 'he', 'certainly', 'does', 'not', 'intend', 'to', 'abolish', 'divine', 'standards', 'of', 'conduct', 'on', 'the', 'other', 'hand', 'when', 'jesus', 'commends', 'the', 'law', 'he', 'seems', 'to', 'be', 'talking', 'the', 'law', 'in', 'its', 'broadest', 'implications', 'for', 'morals', 'and', 'human', 'relationships', 'and', 'deemphasizing', 'those', 'aspects', 'that', 'were', 'later', 'to', 'give', 'paul', 'so', 'much', 'trouble', 'it', 'unfortunate', 'that', 'people', 'use', 'the', 'same', 'terms', 'in', 'different', 'ways', 'but', 'we', 'should', 'be', 'familiar', 'with', 'that', 'from', 'current', 'conflicts', 'look', 'at', 'the', 'way', 'terms', 'like', 'family', 'values', 'take', 'on', 'special', 'meaning', 'from', 'the', 'current', 'context', 'imagine', 'some', 'poor', 'historian', 'of', 'the', 'future', 'trying', 'to', 'figure', 'out', 'why', 'family', 'values', 'should', 'be', 'used', 'as', 'code', 'word', 'for', 'opposition', 'to', 'homosexuality', 'in', 'one', 'specific', 'period', 'in', 'the', 'think', 'law', 'had', 'taken', 'on', 'similar', 'role', 'in', 'the', 'arguments', 'paul', 'was', 'involved', 'in', 'paul', 'was', 'clearly', 'not', 'rejecting', 'all', 'of', 'the', 'jewish', 'values', 'that', 'go', 'along', 'with', 'the', 'term', 'law', 'any', 'more', 'than', 'people', 'who', 'concerned', 'about', 'the', 'family', 'values', 'movement', 'are', 'really', 'opposed', 'to', 'family', 'values'], tags=[0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=30, min_count=2, epochs=40, window=2)\n",
    "model.build_vocab(train_corpus)\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {}\n",
    "inferred_vectors_test = {} # Contains, category-wise, inferred doc vecs for each document in the test set\n",
    "for cat, docs in cat_dict_test_clean.items():\n",
    "    inferred_vectors_test[cat] = [model.infer_vector(doc) for doc in list(docs)]\n",
    "    metadata[cat] = len(inferred_vectors_test[cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_to_csv(input, output_file, delimiter='\\t'):\n",
    "    with open(output_file, \"w\") as f:\n",
    "        writer = csv.writer(f, delimiter=delimiter)\n",
    "        writer.writerows(input)\n",
    "        \n",
    "veclist_metadata = []\n",
    "veclist = []\n",
    "for cat in cat_dict.keys():\n",
    "    for tag in [cat]*metadata[cat]:\n",
    "        veclist_metadata.append([tag])\n",
    "    for vec in inferred_vectors_test[cat]:\n",
    "        veclist.append(list(vec))\n",
    "write_to_csv(veclist, \"doc2vec_20Newsgroups_vectors.csv\")\n",
    "write_to_csv(veclist_metadata, \"doc2vec_20Newsgroups_vectors_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вектор для документа 0: [-5.2308156e-03 -5.9791268e-03 -9.8807542e-03  8.5528456e-03\n",
      "  3.5661161e-03  2.6303172e-04 -9.8806275e-03 -5.1666484e-03\n",
      " -9.7179627e-03  2.0107795e-03  2.8303110e-03  4.6435557e-03\n",
      " -4.2972756e-03 -3.1457066e-03 -3.0787874e-03 -8.7219151e-03\n",
      "  2.1724831e-03  9.2256228e-03 -9.5018670e-03 -3.4580862e-03\n",
      " -3.7699090e-03  2.6073826e-03 -5.6915567e-03  2.6206803e-03\n",
      "  5.8025215e-03 -8.1068603e-03 -8.3297910e-03 -9.9546695e-03\n",
      "  4.9330448e-03 -9.1223074e-03  5.8419635e-03  6.8002627e-03\n",
      " -6.5064002e-03 -4.5198812e-03 -1.2548614e-03  1.6463208e-03\n",
      " -1.4813376e-03 -8.5425414e-03 -3.6026132e-03  1.7316258e-03\n",
      " -2.0569193e-03 -7.2300420e-03  4.1846000e-03 -8.5743405e-03\n",
      "  2.7115368e-03 -4.6137203e-03  6.4542773e-04 -2.0573472e-03\n",
      "  5.4132282e-03 -8.0025708e-03 -2.1198511e-03 -9.5815660e-05\n",
      " -6.6387774e-03 -6.5261638e-03 -1.9329584e-03  8.8034747e-03\n",
      " -1.2631691e-03  3.5359799e-03 -5.7503129e-03  8.8148145e-03\n",
      "  2.9154683e-03  9.2796851e-03  4.3498552e-03 -4.1995691e-03\n",
      "  2.2419060e-03 -4.4124555e-03  5.7769404e-03  1.8315231e-03\n",
      " -2.2787608e-03 -5.8811186e-03 -8.0270842e-03 -8.5307239e-04\n",
      " -8.9393631e-03 -9.2236344e-03 -7.9399096e-03  2.1690738e-03\n",
      " -6.5009403e-03 -7.7883434e-03  2.1311676e-03  2.0526624e-03\n",
      "  8.3483569e-03  4.6679149e-03 -9.4101038e-03 -3.3878087e-04\n",
      "  7.8540277e-03  2.6714755e-03  2.6803636e-03 -4.8837112e-03\n",
      "  6.4671705e-03  1.6488147e-03 -7.6021445e-03  6.8639722e-03\n",
      " -9.7693978e-03 -8.1585944e-03 -4.8741638e-03  9.9376775e-03\n",
      "  3.1130922e-03 -2.0120370e-03  8.8951699e-03  2.3512566e-03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Igorexy\\AppData\\Local\\Temp\\ipykernel_19892\\3094367782.py:19: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  vector_for_doc_0 = model.docvecs['0']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Предположим, что у вас есть список текстов\n",
    "texts = [\n",
    "    \"Текст 1\",\n",
    "    \"Текст 2\",\n",
    "    \"Текст 3\",\n",
    "    # добавьте ваши тексты здесь\n",
    "]\n",
    "\n",
    "# Подготовьте тексты в формате TaggedDocument\n",
    "documents = [TaggedDocument(words=text.split(), tags=[str(i)]) for i, text in enumerate(texts)]\n",
    "\n",
    "# Инициализируйте и обучите модель Doc2Vec\n",
    "model = Doc2Vec(documents, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Теперь вы можете получить векторное представление для каждого документа\n",
    "# Например, для документа с индексом 0\n",
    "vector_for_doc_0 = model.docvecs['0']\n",
    "print(\"Вектор для документа 0:\", vector_for_doc_0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
